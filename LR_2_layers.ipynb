{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#THIS PROGRAM BUILDS A NEURAL NETWORK WITH 2 LAYERS; \n",
    "#THE FIRS LAYER HAS 9 WEIGHTS CORRESPONDING TO EACH OF THE 9 PREDICTOR VARIABLES;\n",
    "#THE SECOND HIDDEN LAYER HAS 5 WEIGHTS, WHICH IS THE MEAN OF (9,1)/2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from math import floor, ceil\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on test set; \n",
    "def return_pred(pred_logits): \n",
    "    sig = 1/(1+np.exp(-pred_logits))\n",
    "    res = np.zeros(sig.shape)\n",
    "    res[sig > 0.5] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For more information on the dataset: \n",
    "#https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "data = np.genfromtxt(\"breast-cancer-wisconsin.data\",delimiter=',',dtype=int,missing_values=-1)\n",
    "data = data.astype(float)\n",
    "N = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 12)\n"
     ]
    }
   ],
   "source": [
    "#Convert the categorization to 2-> 0 (benign),4-> 1 (malignant)\n",
    "x = np.zeros((N,1),dtype=float)\n",
    "x[data[:,10] > 2] = 1\n",
    "data = np.hstack((data,x))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "batch_size = 50\n",
    "learning_rate = 0.01\n",
    "n_epochs = 500\n",
    "frac = 0.6 #fraction of original dataset used to train, the rest for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test datasets\n",
    "#80 percent of the shape will be used for training, the test for testing\n",
    "np.random.shuffle(data)\n",
    "train_data = data[:floor(frac*N)]\n",
    "test_data = data[ceil(frac*N)-1:]\n",
    "# Delete the training ID and original label (index 10) \n",
    "train_data = train_data[:,1:]\n",
    "train_data = np.delete(train_data,9,axis=1)\n",
    "test_data  = test_data[:,1:]\n",
    "test_data  = np.delete(test_data,9,axis=1)\n",
    "#Split into predictors and labels; there are 9 predictors and 1 label\n",
    "train_x,train_y = train_data[:,:9],train_data[:,9].reshape(-1,1)\n",
    "test_x,test_y   = test_data[:,:9],test_data[:,9].reshape(-1,1)\n",
    "#Save the number of observations used to train or test\n",
    "N_train = train_data.shape[0]\n",
    "N_test = test_data.shape[0]\n",
    "# #Convert to tensor for appropriate type conversion later\n",
    "# train_x,train_y = tf.convert_to_tensor(train_x,dtype=tf.float64),tf.convert_to_tensor(train_y,dtype=tf.float64)\n",
    "# test_x,test_y = tf.convert_to_tensor(test_x),tf.convert_to_tensor(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data into tensor\n",
    "train = tf.data.Dataset.from_tensor_slices((train_x,train_y))\n",
    "train = train.shuffle(N_train)\n",
    "train = train.batch(batch_size)\n",
    "test  = tf.data.Dataset.from_tensor_slices((test_x,test_y))\n",
    "test  = test.shuffle(N_test)\n",
    "# test  = test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create iterator \n",
    "iterator = tf.data.Iterator.from_structure(train.output_types,train.output_shapes)\n",
    "feat,label = iterator.get_next()\n",
    "train_init = iterator.make_initializer(train)\n",
    "# test_init = iterator.make_initializer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Create weights and biases\n",
    "w1 = tf.get_variable(name=\"weights1\",shape=(9,1),dtype=tf.float64,\n",
    "                    initializer=tf.random_normal_initializer(mean=0.0,stddev=0.001))\n",
    "b1 = tf.get_variable(name=\"biases1\",shape=(1,1),dtype=tf.float64,initializer=tf.zeros_initializer()) \n",
    "w2 = tf.get_variable(name=\"weights2\",shape=(5,1),dtype=tf.float64,\n",
    "                    initializer = tf.random_normal_initializer(mean=0.0,stddev=0.0001))\n",
    "b2 = tf.get_variable(name=\"biases2\",shape=(1,1),dtype=tf.float64,\n",
    "                    initializer=tf.random_normal_initializer(mean=0.0,stddev=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Build the model\n",
    "logits1 = tf.matmul(feat, w1) + b1\n",
    "logits2 = tf.reshape(tf.reduce_sum(tf.matmul(logits1, tf.transpose(w2)),axis=1),(-1,1)) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Define loss function\n",
    "entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits2,labels=label,name=\"entropy\")\n",
    "loss = tf.reduce_mean(entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Define training model \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Train the model\n",
    "# preds = tf.zeros_like(logits)\n",
    "# update = tf.where(tf.greater(logits,0.5))\n",
    "# preds = preds.assign(update,1)\n",
    "preds = tf.round(tf.sigmoid(logits2))\n",
    "correct = tf.equal(tf.argmax(preds,1),tf.argmax(label,1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the graph\n",
    "writer = tf.summary.FileWriter('./graphs/logreg',tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THE MODEL \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())#MUST INITILIZE ALL VARIABLES\n",
    "     # train the model n_epochs times\n",
    "    for i in range(n_epochs): \t\n",
    "#         print(\"Iteration:\",i)\n",
    "        sess.run(train_init)\t# drawing samples from train_data\n",
    "        sess.run([optimizer,loss])\n",
    "    \n",
    "    #test the model after getting the finalized set of weights\n",
    "    final_w1 = sess.run(w1)\n",
    "    final_b1 = sess.run(b1)\n",
    "    final_w2 = sess.run(w2)\n",
    "    final_b2 = sess.run(b2)\n",
    "#     print(result.shape)\n",
    "#     print(test_y.T)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:96.43%\n"
     ]
    }
   ],
   "source": [
    "pred_logit1 = np.matmul(test_x,final_w1) + final_b1\n",
    "pred_logit =  np.sum(np.matmul(pred_logit1, final_w2.T),axis=1).reshape(-1,1) + final_b2\n",
    "test_pred = return_pred(pred_logit)\n",
    "test_acc = np.sum(test_pred == test_y)/N_test\n",
    "print(\"Accuracy on test set:{}%\".format(round(test_acc*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_w1: [[-0.0893304 ]\n",
      " [-0.08144471]\n",
      " [-0.07039969]\n",
      " [-0.06893254]\n",
      " [ 0.01253474]\n",
      " [-0.07734862]\n",
      " [-0.08362063]\n",
      " [-0.05578043]\n",
      " [-0.02982336]]\n",
      "Final_b1: [[1.87783155]]\n",
      "Final_w2: [[-0.694006  ]\n",
      " [-0.69408433]\n",
      " [-0.69413159]\n",
      " [-0.6940172 ]\n",
      " [-0.69382536]]\n",
      "Final_b2: [[-1.0656425]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final_w1:\",final_w1)\n",
    "print(\"Final_b1:\",final_b1)\n",
    "print(\"Final_w2:\",final_w2)\n",
    "print(\"Final_b2:\",final_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "275.71px",
    "left": "937.182px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

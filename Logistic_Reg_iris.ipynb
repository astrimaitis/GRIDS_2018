{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from math import floor, ceil\n",
    "import logistic \n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on test set; \n",
    "def return_pred(pred_logits): \n",
    "    sig = 1/(1+np.exp(-pred_logits))\n",
    "    res = np.zeros(sig.shape)\n",
    "    res[sig > 0.5] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import data from CSCI 567 Assignment 2 Iris dataset;\n",
    "from data_loader import toy_data_binary as toy\n",
    "train_x, test_x, train_y, test_y = toy()\n",
    "train_y = train_y.astype(float)\n",
    "test_y  = test_y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert the categorization to 2-> 0 (benign),4-> 1 (malignant)\n",
    "# x = np.zeros((N,1),dtype=float)\n",
    "# x[data[:,10] > 2] = 1\n",
    "# data = np.hstack((data,x))\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parameters\n",
    "batch_size = train_x.shape[0]\n",
    "learning_rate = 0.05\n",
    "n_epochs = 1000\n",
    "frac = 0.30 #fraction of original dataset used to train, the rest for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test datasets\n",
    "train_y,test_y = train_y.reshape(-1,1),test_y.reshape(-1,1)\n",
    "#Save the number of observations used to train or test\n",
    "N_train = train_x.shape[0]\n",
    "N_test = test_x.shape[0]\n",
    "# #Convert to tensor for appropriate type conversion later\n",
    "# train_x,train_y = tf.convert_to_tensor(train_x,dtype=tf.float64),tf.convert_to_tensor(train_y,dtype=tf.float64)\n",
    "# test_x,test_y = tf.convert_to_tensor(test_x),tf.convert_to_tensor(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data into tensor\n",
    "train = tf.data.Dataset.from_tensor_slices((train_x,train_y))\n",
    "train = train.shuffle(N_train)\n",
    "train = train.batch(batch_size)\n",
    "test  = tf.data.Dataset.from_tensor_slices((test_x,test_y))\n",
    "test  = test.shuffle(N_test)\n",
    "# test  = test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create iterator \n",
    "iterator = tf.data.Iterator.from_structure(train.output_types,train.output_shapes)\n",
    "feat,label = iterator.get_next()\n",
    "train_init = iterator.make_initializer(train)\n",
    "# test_init = iterator.make_initializer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Create weights and biases\n",
    "w = tf.get_variable(name=\"weights\",shape=(2,1),dtype=tf.float64,\n",
    "                    initializer=tf.random_normal_initializer(mean=0.0,stddev=0.001))\n",
    "b = tf.get_variable(name=\"biases\",shape=(1,1),dtype=tf.float64,initializer=tf.zeros_initializer())             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Build the model\n",
    "logits = tf.matmul(tf.cast(feat,dtype=tf.float64),w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Define loss function\n",
    "entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=label,name=\"entropy\")\n",
    "loss = tf.reduce_mean(entropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Define training model \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Train the model\n",
    "# preds = tf.zeros_like(logits)\n",
    "# update = tf.where(tf.greater(logits,0.5))\n",
    "# preds = preds.assign(update,1)\n",
    "preds = tf.round(tf.sigmoid(logits))\n",
    "correct = tf.equal(tf.argmax(preds,1),tf.argmax(label,1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output the graph\n",
    "writer = tf.summary.FileWriter('./graphs/logreg',tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THE MODEL \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())#MUST INITILIZE ALL VARIABLES\n",
    "     # train the model n_epochs times\n",
    "    for i in range(n_epochs): \t\n",
    "#         print(\"Iteration:\",i)\n",
    "        sess.run(train_init)\t# drawing samples from train_data\n",
    "        sess.run([optimizer,loss])\n",
    "    \n",
    "    #test the model after getting the finalized set of weights\n",
    "    final_w = sess.run(w)\n",
    "    final_b = sess.run(b)\n",
    "#     print(result.shape)\n",
    "#     print(test_y.T)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on TRAIN set:99.42857%\n",
      "Accuracy on TEST set:100.0%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on Training Set\n",
    "train_pred = return_pred(np.matmul(train_x,final_w) + final_b)\n",
    "train_acc = np.sum(train_pred == train_y)/N_train\n",
    "print(\"Accuracy on TRAIN set:{}%\".format(round(train_acc*100,5)))\n",
    "#Accuracy on Test Set\n",
    "test_pred = return_pred(np.matmul(test_x,final_w) + final_b)\n",
    "test_acc = np.sum(test_pred == test_y)/N_test\n",
    "print(\"Accuracy on TEST set:{}%\".format(round(test_acc*100,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "275.71px",
    "left": "937.182px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
